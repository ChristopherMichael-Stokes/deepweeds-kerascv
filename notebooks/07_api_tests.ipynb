{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import httpx\n",
    "from PIL import Image\n",
    "import io\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.11.11 environment at: /home/chris/repos/deepweeds-kerascv/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 3ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batch(n_batch: int):\n",
    "    images = []\n",
    "    for _ in range(n_batch):\n",
    "        img_bytes = io.BytesIO()\n",
    "        data = np.random.uniform(0, 255, (256, 256, 3)).astype(np.uint8)\n",
    "        Image.fromarray(data).save(img_bytes, \"JPEG\")\n",
    "        img_bytes.seek(0)\n",
    "        images.append(img_bytes)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get baselines running inference directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_session(providers: list[str | tuple[str, dict]]):\n",
    "    onnx_session = ort.InferenceSession(\"../models/MeNet.onnx\", providers=providers)\n",
    "    onnx_input_name = onnx_session.get_inputs()[0].name\n",
    "    onnx_output_name = onnx_session.get_outputs()[0].name\n",
    "    preload_sample = np.random.uniform(0, 255, (1, 256, 256, 3)).astype(np.float32)\n",
    "    onnx_session.run([onnx_output_name], {onnx_input_name: preload_sample})\n",
    "    return onnx_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_session = make_session(providers=[\"TensorrtExecutionProvider\"])\n",
    "onnx_input_name = onnx_session.get_inputs()[0].name\n",
    "onnx_output_name = onnx_session.get_outputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.93 ms ± 37.6 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preload_sample = np.random.uniform(0, 255, (1, 256, 256, 3)).astype(np.float32)\n",
    "_ = onnx_session.run([onnx_output_name], {onnx_input_name: preload_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7a485da66a4d50a030c6199478206d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = [\n",
    "    np.random.uniform(0, 255, (1, 256, 256, 3)).astype(np.float32)\n",
    "    for _ in range(BATCH_SIZE)\n",
    "]\n",
    "for img in tqdm(images):\n",
    "    _ = onnx_session.run([onnx_output_name], {onnx_input_name: img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del onnx_session\n",
    "onnx_session = make_session(\n",
    "    providers=[(\"TensorrtExecutionProvider\", {\"trt_fp16_enable\": True})]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.71 ms ± 93.9 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preload_sample = np.random.uniform(0, 255, (1, 256, 256, 3)).astype(np.float32)\n",
    "_ = onnx_session.run([onnx_output_name], {onnx_input_name: preload_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70332fb70a944bd69edcc85fb9829a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = [\n",
    "    np.random.uniform(0, 255, (1, 256, 256, 3)).astype(np.float32)\n",
    "    for _ in range(BATCH_SIZE)\n",
    "]\n",
    "for img in tqdm(images):\n",
    "    _ = onnx_session.run([onnx_output_name], {onnx_input_name: img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del onnx_session\n",
    "onnx_session = make_session(providers=[\"CUDAExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.81 ms ± 568 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preload_sample = np.random.uniform(0, 255, (1, 256, 256, 3)).astype(np.float32)\n",
    "_ = onnx_session.run([onnx_output_name], {onnx_input_name: preload_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63a2e4ff78cc419eb843719dbf361f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = [\n",
    "    np.random.uniform(0, 255, (1, 256, 256, 3)).astype(np.float32)\n",
    "    for _ in range(BATCH_SIZE)\n",
    "]\n",
    "for img in tqdm(images):\n",
    "    _ = onnx_session.run([onnx_output_name], {onnx_input_name: img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del onnx_session\n",
    "onnx_session = make_session(providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.5 ms ± 5.91 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "preload_sample = np.random.uniform(0, 255, (1, 256, 256, 3)).astype(np.float32)\n",
    "_ = onnx_session.run([onnx_output_name], {onnx_input_name: preload_sample})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49af0a492034f62bbbf2157fc2dfe64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = [\n",
    "    np.random.uniform(0, 255, (1, 256, 256, 3)).astype(np.float32)\n",
    "    for _ in range(BATCH_SIZE)\n",
    "]\n",
    "for img in tqdm(images):\n",
    "    _ = onnx_session.run([onnx_output_name], {onnx_input_name: img})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Results running inference through our fastapi endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.87 ms ± 142 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "img_bytes = io.BytesIO()\n",
    "data = np.random.uniform(0, 255, (256, 256, 3)).astype(np.uint8)\n",
    "Image.fromarray(data).save(img_bytes, \"JPEG\")\n",
    "img_bytes.seek(0)\n",
    "\n",
    "url = \"http://localhost:8000/predict\"\n",
    "files = {\"file\": (\"image.jpg\", img_bytes, \"image/jpeg\")}\n",
    "\n",
    "response = requests.post(url, files=files)\n",
    "assert response.status_code == 200\n",
    "# print(response.status_code)\n",
    "# print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def send_image_request(image_bytes, client: httpx.AsyncClient):\n",
    "    # Convert numpy array to image bytes\n",
    "    files = {\"file\": (\"image.jpg\", image_bytes, \"image/jpeg\")}\n",
    "    response = await client.post(\"/predict\", files=files)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:09<00:00, 108.86it/s]\n"
     ]
    }
   ],
   "source": [
    "images = gen_batch(BATCH_SIZE // 4)\n",
    "async with httpx.AsyncClient(\n",
    "    base_url=\"http://localhost:8000/\", limits=httpx.Limits(max_connections=1024)\n",
    ") as client:\n",
    "    res = await tqdm_asyncio.gather(\n",
    "        *[send_image_request(image, client) for image in images[:]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTTPX is borked, I've no idea why it's so slow?? - doesn't make any requests with > 1024 coroutines even with a reasonable connection limit (so need to do some extra concurrency control probably), and is worse on both sync and async compared to standard requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = gen_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139d927989be4bf3af034d70b2cd3462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4096 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for img_bytes in tqdm(images):\n",
    "    files = {\"file\": (\"image.jpg\", img_bytes, \"image/jpeg\")}\n",
    "    response = requests.post(\"http://localhost:8000/predict\", files=files)\n",
    "    assert response.status_code == 200, (response.status_code, response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "\n",
    "\n",
    "async def aio_request(img_bytes, session):\n",
    "    data = aiohttp.FormData()\n",
    "    data.add_field(\"file\", img_bytes, filename=\"image.jpg\", content_type=\"image/jpeg\")\n",
    "\n",
    "    async with session.post(\"http://localhost:8000/predict\", data=data) as response:\n",
    "        return await response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:12<00:00, 335.68it/s]\n"
     ]
    }
   ],
   "source": [
    "images = gen_batch(BATCH_SIZE)\n",
    "async with aiohttp.ClientSession() as session:\n",
    "    res = await tqdm_asyncio.gather(\n",
    "        *[aio_request(image, session) for image in images[:]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our gpu usage is never above ~50% even through the high request rate, so data throughput / python overhead is a hard-limit - we can't feed the model fast enough.  Bumping the number of processes will ease this but annoyingly we need a separate model instance for each, maybe this would be not be a problem if we switched to a language that allows parallel threads\n",
    "\n",
    "Running the server with 4x uvicorn workers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4096/4096 [00:04<00:00, 833.67it/s]\n"
     ]
    }
   ],
   "source": [
    "images = gen_batch(BATCH_SIZE)\n",
    "async with aiohttp.ClientSession() as session:\n",
    "    res = await tqdm_asyncio.gather(\n",
    "        *[aio_request(image, session) for image in images[:]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Halves the runtime but 4x's the vram usage (way under the limit anyway though so we're fine, but for sure not ideal with larger models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas to experiment with in random order:\n",
    "\n",
    "1. Try an optimised inference service that does clever things I don't have time to implement - (nvidia Triton, TFServing...)\n",
    "2. Try to figure out how to make the onnx inference session async compatible\n",
    "3. If no luck try to re-write inference service in cpp with threading & async (as opposed to async only) on the prediction endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
